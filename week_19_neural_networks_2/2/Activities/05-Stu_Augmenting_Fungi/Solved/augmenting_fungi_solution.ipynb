{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":10900,"status":"ok","timestamp":1717218423420,"user":{"displayName":"Alexander Booth","userId":"02269714993535573104"},"user_tz":300},"id":"38VsRPnj4Riy"},"outputs":[],"source":["import tensorflow as tf\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","import requests\n","import numpy as np\n","import pandas as pd\n","import io\n","import pickle"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7073,"status":"ok","timestamp":1717218430491,"user":{"displayName":"Alexander Booth","userId":"02269714993535573104"},"user_tz":300},"id":"NWpxhLKL1XI1","outputId":"22a43958-5761-43a8-da64-30d499ac6ce2"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[0.5568628  0.5647059  0.56078434]\n","  [0.5568628  0.5647059  0.56078434]\n","  [0.5568628  0.5647059  0.56078434]\n","  ...\n","  [0.53333336 0.54901963 0.54509807]\n","  [0.5372549  0.5529412  0.54901963]\n","  [0.5372549  0.5529412  0.54901963]]\n","\n"," [[0.54901963 0.5568628  0.5529412 ]\n","  [0.54901963 0.5568628  0.5529412 ]\n","  [0.5529412  0.56078434 0.5568628 ]\n","  ...\n","  [0.53333336 0.54901963 0.54509807]\n","  [0.5372549  0.5529412  0.54901963]\n","  [0.5372549  0.5529412  0.54901963]]\n","\n"," [[0.53333336 0.5411765  0.5372549 ]\n","  [0.5411765  0.54901963 0.54509807]\n","  [0.54901963 0.5568628  0.5529412 ]\n","  ...\n","  [0.5254902  0.5411765  0.5372549 ]\n","  [0.5294118  0.54509807 0.5411765 ]\n","  [0.5294118  0.54509807 0.5411765 ]]\n","\n"," ...\n","\n"," [[0.5529412  0.53333336 0.4509804 ]\n","  [0.5529412  0.53333336 0.4509804 ]\n","  [0.54901963 0.5254902  0.44705883]\n","  ...\n","  [0.54509807 0.5529412  0.5568628 ]\n","  [0.54509807 0.5529412  0.56078434]\n","  [0.54509807 0.5529412  0.56078434]]\n","\n"," [[0.54901963 0.5254902  0.44705883]\n","  [0.54901963 0.5254902  0.44705883]\n","  [0.5411765  0.5176471  0.44313726]\n","  ...\n","  [0.5411765  0.5568628  0.56078434]\n","  [0.5411765  0.5568628  0.56078434]\n","  [0.5411765  0.5568628  0.56078434]]\n","\n"," [[0.54901963 0.52156866 0.44705883]\n","  [0.54901963 0.52156866 0.44705883]\n","  [0.5411765  0.5176471  0.44313726]\n","  ...\n","  [0.5411765  0.5568628  0.56078434]\n","  [0.5411765  0.5568628  0.56078434]\n","  [0.5411765  0.5568628  0.56078434]]]\n","0    H1\n","1    H1\n","2    H2\n","3    H1\n","4    H2\n","dtype: object\n"]}],"source":["# Import the preprocessed data\n","X_preprocessed_url = \"https://static.bc-edx.com/ai/ail-v-1-0/m19/lesson_2/datasets/pickles/preprocessed_fungi.pkl\"\n","y_url = \"https://static.bc-edx.com/ai/ail-v-1-0/m19/lesson_2/datasets/pickles/fungi_y.pkl\"\n","\n","X = pickle.load(io.BytesIO(requests.get(X_preprocessed_url).content))\n","y = pickle.load(io.BytesIO(requests.get(y_url).content))\n","\n","print(X[0])\n","print(y.head())"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2089,"status":"ok","timestamp":1717218432577,"user":{"displayName":"Alexander Booth","userId":"02269714993535573104"},"user_tz":300},"id":"uAc56Hf61he_"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","\n","# Label encode the y data\n","y_encoder = LabelEncoder().fit(y)\n","y = y_encoder.transform(y)\n","\n","# Convert values to numpy arrays\n","X = np.array(X)\n","\n","# Split the training dataset into training and validation sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":132,"status":"ok","timestamp":1717218432707,"user":{"displayName":"Alexander Booth","userId":"02269714993535573104"},"user_tz":300},"id":"1fQWn9ym6E__"},"outputs":[],"source":["# Define the augmentation pipeline\n","data_augmentation = tf.keras.Sequential([\n","    tf.keras.layers.RandomRotation(0.2),         # Random rotation (20 degrees)\n","    tf.keras.layers.RandomTranslation(0.1, 0.1), # Random horizontal and vertical shift\n","    tf.keras.layers.RandomZoom(0.2),             # Random zoom\n","    tf.keras.layers.RandomFlip('horizontal')     # Random horizontal flip\n","])"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45026,"status":"ok","timestamp":1717218477732,"user":{"displayName":"Alexander Booth","userId":"02269714993535573104"},"user_tz":300},"id":"SnTv2j_f6yZd","outputId":"a8a1199b-0027-4165-a372-4ddf78044d05"},"outputs":[{"name":"stdout","output_type":"stream","text":["1000\n","1000\n"]}],"source":["# Create an empty list for X and y augmentations\n","X_train_aug = []\n","y_train_aug = []\n","\n","# Loop through the entire X_train set\n","for i in range(len(X_train)):\n","    # Select the original image and its y label\n","    img = X_train[i]\n","    label = y_train[i]\n","\n","    # Ensure that the input data has the correct shape\n","    img = np.expand_dims(img, axis=0)  # Add batch dimension\n","\n","    # Add 5 new images for every original\n","    for j in range(5):\n","        # Create and append the image\n","        X_train_aug.append(data_augmentation(img, training=True)[0].numpy())\n","        # Append the original label\n","        y_train_aug.append(label)\n","\n","# Print the length of the augmented images and the labels\n","print(len(X_train_aug))\n","print(len(y_train_aug))"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39324,"status":"ok","timestamp":1717218517047,"user":{"displayName":"Alexander Booth","userId":"02269714993535573104"},"user_tz":300},"id":"4rAh8qXo2x7G","outputId":"07bb58e7-2646-47a9-ca4a-f399d7963048"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Export our final variables to a pickle file using a dictionary\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Create the dictionary\n","fungi_dict = {\n","    'X_train': X_train_aug,\n","    'X_test': X_test,\n","    'y_train': y_train_aug,\n","    'y_test': y_test\n","}\n","\n","# Store the dictionary in a pickle file\n","with open('/content/drive/My Drive/fungi_dict.pkl', 'wb') as file:\n","    pickle.dump(fungi_dict, file)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
