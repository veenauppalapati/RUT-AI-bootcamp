{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Un6tNZhrN_3q"
   },
   "source": [
    "# 1. Import the Preprocessed Data\n",
    "Import the pickle file with the preprocessed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tSIn8ESYLpB5",
    "outputId": "9f99114a-7a4e-4a8d-d86d-36ffd67d5b14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X_train', 'X_test', 'y_train_userid', 'y_train_pose', 'y_train_expression', 'y_train_eyes', 'y_test_userid', 'y_test_pose', 'y_test_expression', 'y_test_eyes'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import requests\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pickle_file = 'https://static.bc-edx.com/ai/ail-v-1-0/m19/lesson_3/datasets/pickles/preprocessed_faces_data.pkl'\n",
    "response = requests.get(pickle_file)\n",
    "data = pd.read_pickle(io.BytesIO(response.content))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eDFj4qXRNomz"
   },
   "outputs": [],
   "source": [
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "\n",
    "y_train_userid = data['y_train_userid']\n",
    "y_train_pose = data['y_train_pose']\n",
    "y_train_expression = data['y_train_expression']\n",
    "y_train_eyes = data['y_train_eyes']\n",
    "\n",
    "y_test_userid = data['y_test_userid']\n",
    "y_test_pose = data['y_test_pose']\n",
    "y_test_expression = data['y_test_expression']\n",
    "y_test_eyes = data['y_test_eyes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYtrr4IDoUAw"
   },
   "source": [
    "# 2. Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zyyus3qUnpkx"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, Model\n",
    "# First we build the input layer\n",
    "input_layer = layers.Input(shape=(60, 64, 1), name='input_layer')\n",
    "\n",
    "# Shared layers (common across all tasks)\n",
    "# The second layer should be a Conv2D layer built off the input_layer\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "\n",
    "# The third layer should be a MaxPooling2D layer built off the second layer\n",
    "maxpool1 = layers.MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "# The fourth layer should be a Conv2D layer built off the third layer\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu')(maxpool1)\n",
    "\n",
    "# The fifth layer should be a MaxPooling2D layer built off the fourth layer\n",
    "maxpool2 = layers.MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "# The sixth layer should be a Conv2D layer built off the fifth layer\n",
    "conv3 = layers.Conv2D(64, (3, 3), activation='relu')(maxpool2)\n",
    "\n",
    "# The seventh layer should be a Flatten layer built off the sixth layer\n",
    "flatten = layers.Flatten()(conv3)\n",
    "\n",
    "# Lastly, build one dense layer before branching to the different y branches\n",
    "dense_shared = layers.Dense(64, activation='relu')(flatten)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eAEw8LXNpm-R"
   },
   "outputs": [],
   "source": [
    "# Build the branches for each of the y variables\n",
    "# Include a dense hidden layer in each along with the output layer.\n",
    "# Remember to include the correct number of nodes for the output!\n",
    "\n",
    "# userid\n",
    "userid_dense = layers.Dense(64, activation='relu')(dense_shared)\n",
    "userid_output = layers.Dense(len(y_train_userid.columns),\n",
    "                             activation='sigmoid',\n",
    "                             name='userid_output')(userid_dense)\n",
    "\n",
    "# pose\n",
    "pose_dense = layers.Dense(64, activation='relu')(dense_shared)\n",
    "pose_output = layers.Dense(len(y_train_pose.columns),\n",
    "                           activation='softmax',\n",
    "                             name='pose_output')(pose_dense)\n",
    "\n",
    "# expression\n",
    "expression_dense = layers.Dense(64, activation='relu')(dense_shared)\n",
    "expression_output = layers.Dense(len(y_train_expression.columns),\n",
    "                                 activation='softmax',\n",
    "                             name='expression_output')(expression_dense)\n",
    "\n",
    "# eyes\n",
    "eyes_dense = layers.Dense(64, activation='relu')(dense_shared)\n",
    "eyes_output = layers.Dense(len(y_train_eyes.columns),\n",
    "                           activation='sigmoid',\n",
    "                             name='eyes_output')(eyes_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YMUUccPe2LRK"
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Model(inputs=input_layer, outputs=[\n",
    "    userid_output,\n",
    "    pose_output,\n",
    "    expression_output,\n",
    "    eyes_output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'userid_output': 'categorical_crossentropy',\n",
    "                    'pose_output': 'categorical_crossentropy',\n",
    "                    'expression_output': 'categorical_crossentropy',\n",
    "                    'eyes_output': 'binary_crossentropy'},\n",
    "              metrics={'userid_output': 'accuracy',\n",
    "                       'pose_output': 'accuracy',\n",
    "                       'expression_output': 'accuracy',\n",
    "                       'eyes_output': 'accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gnRnEcWB3gb2",
    "outputId": "843fddba-91d5-4af2-91b8-166423c127b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 99ms/step - expression_output_accuracy: 0.2929 - eyes_output_accuracy: 0.5116 - loss: 6.4403 - pose_output_accuracy: 0.2776 - userid_output_accuracy: 0.0630 - val_expression_output_accuracy: 0.2692 - val_eyes_output_accuracy: 0.7500 - val_loss: 5.9636 - val_pose_output_accuracy: 0.4167 - val_userid_output_accuracy: 0.1603\n",
      "Epoch 2/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - expression_output_accuracy: 0.2849 - eyes_output_accuracy: 0.7141 - loss: 5.4154 - pose_output_accuracy: 0.4189 - userid_output_accuracy: 0.3246 - val_expression_output_accuracy: 0.2436 - val_eyes_output_accuracy: 0.7735 - val_loss: 4.9836 - val_pose_output_accuracy: 0.4872 - val_userid_output_accuracy: 0.3932\n",
      "Epoch 3/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - expression_output_accuracy: 0.3198 - eyes_output_accuracy: 0.7598 - loss: 4.3680 - pose_output_accuracy: 0.5163 - userid_output_accuracy: 0.5410 - val_expression_output_accuracy: 0.2009 - val_eyes_output_accuracy: 0.7009 - val_loss: 4.6097 - val_pose_output_accuracy: 0.4209 - val_userid_output_accuracy: 0.6132\n",
      "Epoch 4/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - expression_output_accuracy: 0.3543 - eyes_output_accuracy: 0.8101 - loss: 3.5926 - pose_output_accuracy: 0.5998 - userid_output_accuracy: 0.7098 - val_expression_output_accuracy: 0.2436 - val_eyes_output_accuracy: 0.7671 - val_loss: 4.0541 - val_pose_output_accuracy: 0.5962 - val_userid_output_accuracy: 0.6944\n",
      "Epoch 5/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - expression_output_accuracy: 0.3983 - eyes_output_accuracy: 0.8585 - loss: 3.0635 - pose_output_accuracy: 0.6307 - userid_output_accuracy: 0.8191 - val_expression_output_accuracy: 0.2244 - val_eyes_output_accuracy: 0.8098 - val_loss: 3.9404 - val_pose_output_accuracy: 0.5577 - val_userid_output_accuracy: 0.7179\n",
      "Epoch 6/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - expression_output_accuracy: 0.4521 - eyes_output_accuracy: 0.8869 - loss: 2.6156 - pose_output_accuracy: 0.7197 - userid_output_accuracy: 0.8673 - val_expression_output_accuracy: 0.2585 - val_eyes_output_accuracy: 0.8440 - val_loss: 3.8706 - val_pose_output_accuracy: 0.6068 - val_userid_output_accuracy: 0.7756\n",
      "Epoch 7/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - expression_output_accuracy: 0.4662 - eyes_output_accuracy: 0.9269 - loss: 2.2243 - pose_output_accuracy: 0.7694 - userid_output_accuracy: 0.9192 - val_expression_output_accuracy: 0.2628 - val_eyes_output_accuracy: 0.8120 - val_loss: 3.8964 - val_pose_output_accuracy: 0.6175 - val_userid_output_accuracy: 0.7372\n",
      "Epoch 8/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - expression_output_accuracy: 0.5384 - eyes_output_accuracy: 0.9548 - loss: 1.9083 - pose_output_accuracy: 0.8205 - userid_output_accuracy: 0.9349 - val_expression_output_accuracy: 0.2094 - val_eyes_output_accuracy: 0.8291 - val_loss: 3.9692 - val_pose_output_accuracy: 0.6389 - val_userid_output_accuracy: 0.7906\n",
      "Epoch 9/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - expression_output_accuracy: 0.5502 - eyes_output_accuracy: 0.9537 - loss: 1.6205 - pose_output_accuracy: 0.8744 - userid_output_accuracy: 0.9559 - val_expression_output_accuracy: 0.2265 - val_eyes_output_accuracy: 0.8462 - val_loss: 4.3082 - val_pose_output_accuracy: 0.6325 - val_userid_output_accuracy: 0.8077\n",
      "Epoch 10/10\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - expression_output_accuracy: 0.5899 - eyes_output_accuracy: 0.9718 - loss: 1.4410 - pose_output_accuracy: 0.8815 - userid_output_accuracy: 0.9580 - val_expression_output_accuracy: 0.2201 - val_eyes_output_accuracy: 0.8355 - val_loss: 4.3775 - val_pose_output_accuracy: 0.6410 - val_userid_output_accuracy: 0.8034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23343d37150>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with the training data\n",
    "model.fit(\n",
    "    X_train,\n",
    "    {\n",
    "        'userid_output': y_train_userid,\n",
    "        'pose_output': y_train_pose,\n",
    "        'expression_output': y_train_expression,\n",
    "        'eyes_output': y_train_eyes\n",
    "    },\n",
    "    epochs=10,  # You can adjust the number of epochs based on your needs\n",
    "    batch_size=32,  # You can adjust the batch size based on your available memory\n",
    "    validation_split=0.2  # You can specify the validation split if you have a separate validation set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - expression_output_accuracy: 0.1780 - eyes_output_accuracy: 0.8699 - loss: 4.1096 - pose_output_accuracy: 0.7608 - userid_output_accuracy: 0.8880\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the testing data\n",
    "results = model.evaluate(np.array(X_test), {\n",
    "        'userid_output': y_test_userid,\n",
    "        'pose_output': y_test_pose,\n",
    "        'expression_output': y_test_expression,\n",
    "        'eyes_output': y_test_eyes\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
